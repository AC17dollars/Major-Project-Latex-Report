\section*{ABSTRACT}
\addcontentsline{toc}{section}{ABSTRACT}
    This project explores a novel approach to audio-video representation and compression using the Sinusoidal Representation Network (SIREN), an Implicit Neural Representation (INR) model leveraging a sine activation function. Trained on five video datasets with audio, the unified model demonstrates competitive video compression results.The architecture consists of separate audio and video initialization layers, followed by fully connected shared hidden layers. Past the hidden layers, the model branches into three outputs: one for video representation and two for audio processing using Siamese layers, designed to enhance noise reduction. For one of the videos in the dataset, which was 6.08 MiB, the quantized student model achieved a PSNR of 28.7153 dB and an SSIM of 0.7529 for video, and a PSNR of 24.1786 dB with an LSD of 10.6928 dB for audio. Prior to quantization and distillation, the teacher model had achieved a PSNR of 21.88 dB, SSIM of 0.67 for video, and a PSNR of 62.50 dB with an LSD of 7.60 dB for audio. By applying 16-bit quantization and knowledge distillation, the unified model size was reduced significantly from 9.05 MiB to 2.48 MiB while maintaining competitive perceptual quality. Additionally, further compression using LZMA with xz reduced the model size to 2.33 MiB, achieving an overall compression ratio of 2.61. These advancements demonstrate the model's potential as a scalable solution for multimedia compression. Despite its success, challenges remain in optimizing representation of dynamic content, training on larger datasets, and fine-tuning for diverse video types and lengths. These findings underscore SIREN's promise as a unified and efficient framework for multimedia compression.

    \textit{Keywords: Implicit neural representation, Siamese siren, Sine activation, Sinusoidal representation networks}
